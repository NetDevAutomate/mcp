# LiteLLM Proxy Configuration for AWS Labs CI Pipeline
# Connects to local Bedrock proxy for automated code reviews

model_list:
  # Primary code review model - Claude Sonnet 4 (best for code analysis)
  - model_name: claude-sonnet-4
    litellm_params:
      model: claude-sonnet-4
      api_base: http://localhost:4040/v1
      api_key: sk-litellm-bedrock-proxy-2025
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: false
      max_tokens: 200000

  # Fallback models for different tasks
  - model_name: claude-opus-4-1
    litellm_params:
      model: claude-opus-4.1-use1
      api_base: http://localhost:4040/v1
      api_key: sk-litellm-bedrock-proxy-2025
    model_info:
      mode: chat
      supports_function_calling: true
      max_tokens: 200000

  - model_name: nova-premier
    litellm_params:
      model: nova-premier
      api_base: http://localhost:4040/v1
      api_key: sk-litellm-bedrock-proxy-2025
    model_info:
      mode: chat
      max_tokens: 300000

  - model_name: deepseek-r1
    litellm_params:
      model: deepseek-r1
      api_base: http://localhost:4040/v1
      api_key: sk-litellm-bedrock-proxy-2025
    model_info:
      mode: chat
      max_tokens: 130000

# Router configuration for intelligent model selection
router_settings:
  routing_strategy: least-busy
  retry_policy:
    - model: claude-sonnet-4
    - model: claude-opus-4-1
    - model: nova-premier

# General settings
general_settings:
  completion_model: claude-sonnet-4
  max_budget: 100.0
  budget_duration: 24h
